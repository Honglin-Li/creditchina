{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2f7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "theme_classification\n",
    "\n",
    "The module provides data processing, train and tuning, predictions, evaluations in the theme classifications\n",
    "\"\"\"\n",
    "\n",
    "# for jupyter notebook\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parents[0].parents[0]))\n",
    "\n",
    "from src.data_transformation.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23042011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml packages\n",
    "import pickle\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score, recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234a129",
   "metadata": {},
   "source": [
    "# pre-precessing\n",
    "\n",
    "- data source\n",
    "- Chinese cut\n",
    "- word cloud for each theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d766358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_stopwords = [k.strip() for k in open(os.path.join(data_path, 'cn_stopwords.txt'), encoding='utf8').readlines() if k.strip() != '']\n",
    "\n",
    "def cut_phrases(x, sep=' '):\n",
    "    \"\"\"\n",
    "    Cut phrases in ideograms groups by jieba package.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : str\n",
    "        The text to be cut.\n",
    "    sep : str\n",
    "        The separator to join the cut words.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "    \"\"\"\n",
    "    return sep.join([word for word in jieba.cut(x, cut_all=False) if (word not in cn_stopwords) & (len(word) > 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e42c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after manual collection: keywords-theme\n",
    "# authority-map_to->theme, get content-theme datasource\n",
    "def prepare_data_source(df_event, content_col, theme_col): \n",
    "    \"\"\"\n",
    "    Prepare data source for theme classification parallelly.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "    content_col : list of str or str\n",
    "        Each item is the column name of content.\n",
    "    theme_col : str\n",
    "        The column name of authority.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ds_train : DataFrame\n",
    "        The records with themes and content count > 1, contains columns: theme, content, count.\n",
    "    ds_unseen : DataFrame\n",
    "        The records without themes to be predicted, contains columns: theme, content, count, index.\n",
    "    df_train : DataFrame\n",
    "        Straitifing sampled from ds_train(80%)\n",
    "    df_test : DataFrame\n",
    "        Straitifing sampled from ds_train(20%)\n",
    "    \"\"\"        \n",
    "    p = Parallel(n_jobs=cpu_count)\n",
    "    \n",
    "    # theme\n",
    "    df_themes = pd.read_excel(os.path.join(attri_path, 'authority_themes.xlsx'))\n",
    "    \n",
    "    # clean authority\n",
    "    s_clean_authorities = df_event[theme_col].str.replace(r'[0-9a-zA-Z()\\s.-]+', '', regex=True)\n",
    "    \n",
    "    # find match keywords\n",
    "    auth_pattern = re.compile('|'.join(df_themes.keyword))\n",
    "    s_auth_keywords = s_clean_authorities.str.findall(auth_pattern)\n",
    "    \n",
    "    # extract theme\n",
    "    def extract_theme(value):\n",
    "        keyword = np.nan\n",
    "\n",
    "        if (value != value) or len(value) == 0: # value != value-----> nan\n",
    "            return keyword\n",
    "\n",
    "        keyword = value[0]\n",
    "\n",
    "        return df_themes.loc[df_themes.keyword == keyword, 'theme_en'].tolist()[0]\n",
    "    \n",
    "    #s_theme = s_auth_keywords.apply(extract_theme)\n",
    "    s_theme = p(delayed(extract_theme)(x) for x in tqdm(s_auth_keywords.values, desc='extract theme'))\n",
    "    \n",
    "    # content: \n",
    "    \"\"\" somehow parallel_apply throw exception when I run outside this .py\n",
    "    s_content = df_event[content_col].replace(\n",
    "                            r'[0-9a-zA-Z()\\s.-]+', '', regex=True\n",
    "                        ).parallel_apply(lambda row: '.'.join(row.dropna().astype(str)), axis=1) # remove numbers\n",
    "    \"\"\"\n",
    "    connect_func = lambda row: '.'.join(row.dropna().astype(str))\n",
    "    \n",
    "    s_content = p(delayed(connect_func)(row) for i, row in tqdm(df_event[content_col].replace(\n",
    "                            r'[0-9a-zA-Z()\\s.-]+', '', regex=True\n",
    "                        ).iterrows(), desc='connect content'))\n",
    "    \n",
    "    ds = pd.concat({\n",
    "                    'content':pd.Series(s_content), \n",
    "                    'theme': pd.Series(s_theme)\n",
    "                    }, axis=1)\n",
    "    \n",
    "    print(f'{ds.shape[0]} records totally. {ds.theme.isnull().sum()} records have no themes')\n",
    "\n",
    "    print('theme distribution')\n",
    "    draw_bar(ds.theme)\n",
    "    \n",
    "    # cut phrases & count\n",
    "    with parallel_backend('threading', n_jobs=cpu_count):\n",
    "        ds['content'] = Parallel()(delayed(cut_phrases)(x) for x in tqdm(ds.content.values, desc='cut content'))\n",
    "    \n",
    "    ds['count'] = ds.content.str.len()\n",
    "    \n",
    "    # split data set\n",
    "    ds_unseen = ds[ds.theme.isnull()].reset_index() # keep tracking the index\n",
    "    \n",
    "    ds_train = ds[ds.theme.notnull()].reset_index()\n",
    "    \n",
    "    print(f'records without theme: {ds_unseen.shape[0]}; records with theme: {ds_train.shape[0]}')\n",
    "    \n",
    "    # process train data\n",
    "    ds_train = ds_train[ds_train['count'] > 1] # fileter by text counts\n",
    "    \n",
    "    print(f'training set after removing the records with empty content: {ds_train.shape[0]}')\n",
    "    \n",
    "    # split training set to training and test\n",
    "    df_train, df_test = train_test_split(\n",
    "        ds_train[['content', 'theme', 'count']], \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=ds_train['theme'])\n",
    "\n",
    "    return ds_train, ds_unseen, df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d28b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_permit_ds(df_event_permit=None):\n",
    "    \"\"\"\n",
    "    Return the DataFrame for permit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event_permit : DataFrame, default None\n",
    "        if no value, load from local.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ds_train : DataFrame\n",
    "    ds_unseen : DataFrame\n",
    "    df_train : DataFrame\n",
    "    df_test : DataFrame\n",
    "    \"\"\"\n",
    "    if df_event_permit is None:\n",
    "        df_event_permit = pd.read_excel(os.path.join(sub_event_path, '11_event_permit.xlsx'))\n",
    "    \n",
    "    # prepare_permit_ds() needs to much time to run\n",
    "    save_dir = os.path.join(data_path, 'models', 'train')\n",
    "    \n",
    "    if os.path.exists(os.path.join(save_dir, 'permit_ds_train.xlsx')):\n",
    "        # load data\n",
    "        ds_train = pd.read_excel(os.path.join(save_dir, 'permit_ds_train.xlsx'))\n",
    "        ds_unseen = pd.read_excel(os.path.join(save_dir, 'permit_ds_unseen.xlsx'))\n",
    "        df_train = pd.read_excel(os.path.join(save_dir, 'permit_df_train.xlsx'))\n",
    "        df_test = pd.read_excel(os.path.join(save_dir, 'permit_df_test.xlsx'))\n",
    "        \n",
    "        return ds_train, ds_unseen, df_train, df_test\n",
    "    \n",
    "    # create\n",
    "    return prepare_data_source(df_event_permit, \n",
    "                   ['行政许可决定文书名称 Name of Administrative Permission Decision',\n",
    "                    '许可证书名称 Name of Permission Certificate',\n",
    "                    '许可内容 Permission Content'\n",
    "                    ],\n",
    "                    '许可机关 Permission Authority'\n",
    "                   )\n",
    "\n",
    "def prepare_penalty_ds(df_event_penalty=None):\n",
    "    \"\"\"\n",
    "    Return the DataFrame for penalty.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event_penalty : DataFrame, default None\n",
    "        if no value, load from local.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ds_train : DataFrame\n",
    "    ds_unseen : DataFrame\n",
    "    df_train : DataFrame\n",
    "    df_test : DataFrame\n",
    "    \"\"\"\n",
    "    if df_event_penalty is None:\n",
    "        df_event_penalty = pd.read_excel(os.path.join(sub_event_path, '12_event_penalty.xlsx'))\n",
    "        \n",
    "    return prepare_data_source(df_event_penalty, \n",
    "                   ['行政处罚决定书文号 Administrative Penalty Decision Document Number',\n",
    "                    '处罚内容 Penalty Content',\n",
    "                    '违法行为类型 Type of Illegal Behavior',\n",
    "                    '违法事实 Illegal Facts',\n",
    "                    '处罚依据 Penalty Basis'\n",
    "                    ],\n",
    "                    '处罚机关 Penalty Enforcement Authority'\n",
    "                   )\n",
    "\n",
    "def prepare_commitment_ds(df_event_commitment=None):\n",
    "    \"\"\"\n",
    "    Return the DataFrame for credit commitment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event_commitment : DataFrame, default None\n",
    "        if no value, load from local.\n",
    "    s_count : int, default 200\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ds_train : DataFrame\n",
    "    ds_unseen : DataFrame\n",
    "    df_train : DataFrame\n",
    "    df_test : DataFrame\n",
    "    \"\"\"\n",
    "    if df_event_commitment is None:\n",
    "        df_event_commitment = pd.read_excel(os.path.join(sub_event_path, '51_event_commitment_implementation.xlsx'))\n",
    "        \n",
    "    return prepare_data_source(df_event_commitment, \n",
    "                   ['承诺类型 Commitment type',\n",
    "                    '承诺事由 Commitment reason'\n",
    "                    ],\n",
    "                    '承诺受理单位 Commitment processing unit'\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c436b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_table(s_content, word_count=50):\n",
    "    \"\"\"\n",
    "    Get frequency DataFrame from Series s_content with at most word_count words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s_content : Series\n",
    "        The Series contains the content to extract frequency words.\n",
    "    word_count: int, default 50\n",
    "        The value of parameter max_features of CountVectorizer class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_freq : DataFrame\n",
    "        Contains index(word), word_freq, doc_freq columns.\n",
    "    freq_dict : dict\n",
    "        The dict {word: doc_freq} is the input of wordcloud.\n",
    "    \"\"\"\n",
    "    # get doc-word matrix\n",
    "    cv = CountVectorizer(max_features=word_count, stop_words='english')\n",
    "\n",
    "    X = cv.fit_transform(s_content)\n",
    "    \n",
    "    df_count_matrix = pd.DataFrame(X.toarray(), columns = cv.get_feature_names_out())\n",
    "\n",
    "    # frequency\n",
    "    s_freq = df_count_matrix.sum()\n",
    "\n",
    "    s_doc_freq = (df_count_matrix>0).sum()\n",
    "\n",
    "    df_freq = pd.concat({\n",
    "                        'word_freq':s_freq, \n",
    "                        'doc_freq': s_doc_freq\n",
    "                        }, axis=1).sort_values('doc_freq', ascending=False)\n",
    "    \n",
    "    # prepare the input for wordcloud\n",
    "    freq_dict = df_freq.doc_freq.to_dict()\n",
    "    \n",
    "    return df_freq, freq_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce7c7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis word list\n",
    "def show_wordcloud(freq_dict, title = None):\n",
    "    \"\"\"\n",
    "    Show wordcloud.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_dict : dict\n",
    "    title : str\n",
    "    \"\"\"    \n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        font_path=font_path,\n",
    "        max_words=50,\n",
    "        max_font_size=40, \n",
    "        scale=5,\n",
    "        random_state=1\n",
    "    )\n",
    "    \n",
    "    wordcloud.generate_from_frequencies(freq_dict)\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12,12))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=40, fontproperties=prop)\n",
    "        fig.subplots_adjust(top=1.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.savefig(os.path.join(attri_path, 'wordclouds\\\\' + title + '.png'))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f5483",
   "metadata": {},
   "source": [
    "# Classification: Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363b4ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_balanced_training_set(df_train, s_count=200):\\n    \"\\n    Prepare data source for theme classification parallelly.\\n    \\n    Parameters\\n    ----------\\n    df_train : DataFrame\\n        The training set should be a training set in cross-validation.\\n    s_count: int, default 200\\n        The sample count for one theme if the sample_count is lower than s_count, then oversampling to s_count.\\n    \\n    Returns\\n    -------\\n    DataFrame\\n        Return balanced training set\\n    \"    \\n    # balance: get the records with more texts\\n    sample_count = df_train.theme.value_counts().min() # get the minority theme\\n\\n    # downsampling\\n    if sample_count > s_count:\\n        print(f\\'Balancing: Get the top {sample_count} records in each Theme...\\')\\n\\n        ds_train_balanced = df_train.groupby(\\'theme\\').apply(\\n                lambda df: df.sort_values(\\'count\\', ascending=False)[:sample_count]\\n            ).reset_index(drop=True)\\n        \\n        return ds_train_balanced\\n    \\n    # oversampling\\n    print(f\\'{sample_count} records in each Theme is too small, we do oversampling to minorities...\\')\\n\\n    sample_count = s_count\\n\\n    samples = []\\n\\n    for theme, group in df_train.groupby(\\'theme\\'):\\n        if group.shape[0] > sample_count:\\n            # get top 100 by word count\\n            samples.append(group.sort_values(\\'count\\', ascending=False)[:sample_count])\\n        else:\\n            # oversampling\\n            samples.append(group.sample(sample_count, random_state=42, replace=True))\\n\\n    ds_train_balanced = pd.concat(samples, ignore_index=True)\\n\\n    return ds_train_balanced\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_balanced_training_set(df_train, s_count=200):\n",
    "    \"\"\"\n",
    "    Prepare data source for theme classification parallelly.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train : DataFrame\n",
    "        The training set should be a training set in cross-validation.\n",
    "    s_count: int, default 200\n",
    "        The sample count for one theme if the sample_count is lower than s_count, then oversampling to s_count.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Return balanced training set\n",
    "    \"\"\"    \n",
    "    # balance\n",
    "    sample_count = df_train.theme.value_counts().min() # get the minority theme\n",
    "\n",
    "    if sample_count > s_count:\n",
    "        s_count = sample_count\n",
    "        print(f'Balancing: Get the random {s_count} records in each Theme...')\n",
    "\n",
    "    ds_train_balanced = df_train.groupby('theme').apply(\n",
    "        lambda df: df.sample(s_count, random_state=42, replace=True) #df.sort_values('count', ascending=False)[:sample_count]\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    return ds_train_balanced\n",
    "\n",
    "\"\"\"\n",
    "def get_balanced_training_set(df_train, s_count=200):\n",
    "    \"\n",
    "    Prepare data source for theme classification parallelly.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train : DataFrame\n",
    "        The training set should be a training set in cross-validation.\n",
    "    s_count: int, default 200\n",
    "        The sample count for one theme if the sample_count is lower than s_count, then oversampling to s_count.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Return balanced training set\n",
    "    \"    \n",
    "    # balance: get the records with more texts\n",
    "    sample_count = df_train.theme.value_counts().min() # get the minority theme\n",
    "\n",
    "    # downsampling\n",
    "    if sample_count > s_count:\n",
    "        print(f'Balancing: Get the top {sample_count} records in each Theme...')\n",
    "\n",
    "        ds_train_balanced = df_train.groupby('theme').apply(\n",
    "                lambda df: df.sort_values('count', ascending=False)[:sample_count]\n",
    "            ).reset_index(drop=True)\n",
    "        \n",
    "        return ds_train_balanced\n",
    "    \n",
    "    # oversampling\n",
    "    print(f'{sample_count} records in each Theme is too small, we do oversampling to minorities...')\n",
    "\n",
    "    sample_count = s_count\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for theme, group in df_train.groupby('theme'):\n",
    "        if group.shape[0] > sample_count:\n",
    "            # get top 100 by word count\n",
    "            samples.append(group.sort_values('count', ascending=False)[:sample_count])\n",
    "        else:\n",
    "            # oversampling\n",
    "            samples.append(group.sample(sample_count, random_state=42, replace=True))\n",
    "\n",
    "    ds_train_balanced = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "    return ds_train_balanced\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5375905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(ds, t=0, min_df=4, max_df=1000, alpha=0.05, s_count=200):\n",
    "    \"\"\"\n",
    "    Evaluate a estimater with the given hypterparameters by 5 fold cross validation.\n",
    "    Show the classification evaluate resultsand prediction probablity threshold. \n",
    "    The estimator is MultinomialNB.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: DataFrame\n",
    "        The data source contain columns: content and theme(the df_train from func prepare_data_source()).\n",
    "    t : float, default 0\n",
    "        Threshold for prediction probablity. If the maximum prob is lower then t, the class will be marked as -1.\n",
    "    min_df : int or float, default 4\n",
    "    max_df : int or float, default 1000\n",
    "    alpha : float, default 0.05\n",
    "        The hyperparameter of MultinomialNB.\n",
    "    s_count : int, default 200\n",
    "        The minimum sample size requrement.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    acc : float\n",
    "    p : float\n",
    "    r : float\n",
    "    f1 : float\n",
    "    \"\"\"\n",
    "    # encode target\n",
    "    print('encode target...')\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    target = le.fit_transform(ds['theme'])\n",
    "\n",
    "    # 5 folds cross validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
    "\n",
    "    results = pd.DataFrame({'actual': target, 'predicted': 0})\n",
    "    \n",
    "    print('cross validation...')\n",
    "    \n",
    "    for train_indices, test_indices in skf.split(ds['content'], target):\n",
    "        # test\n",
    "        test_data = ds.loc[test_indices, 'content']\n",
    "        y_test = target[test_indices]\n",
    "        \n",
    "        # balance training set\n",
    "        balanced_train_set = get_balanced_training_set(ds.iloc[train_indices], s_count)\n",
    "        \n",
    "        train_data = balanced_train_set['content'] #ds.loc[train_indices, 'content']\n",
    "        y_train = le.transform(balanced_train_set['theme']) #target[train_indices]\n",
    "          \n",
    "        # generate features\n",
    "        print('generate features...')\n",
    "\n",
    "        tfidf = tfidf_vectorizer.fit(train_data)\n",
    "\n",
    "        X_train = pd.DataFrame(tfidf.transform(train_data).toarray(), columns=tfidf.get_feature_names_out())\n",
    "        \n",
    "        print(f'features: {X_train.shape}')\n",
    "\n",
    "        # estimator fit\n",
    "        print('fit estimator...')\n",
    "        clf = MultinomialNB(alpha=alpha)\n",
    "        #clf = SVC(decision_function_shape='ovo')\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        print('predict...')\n",
    "        # features\n",
    "        X_test = pd.DataFrame(tfidf_vectorizer.transform(test_data).toarray(), columns=tfidf.get_feature_names_out())\n",
    "        \n",
    "        y_predicted = None\n",
    "        \n",
    "        if t == 0:\n",
    "            y_predicted = clf.predict(X_test)\n",
    "        else:\n",
    "            y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "            # handle threshold\n",
    "            max_prob = y_prob.max(axis=1)\n",
    "            y_predicted = y_prob.argmax(axis=1)\n",
    "\n",
    "            y_predicted[max_prob < t] = -1\n",
    "\n",
    "        results.loc[test_indices, 'predicted'] = y_predicted\n",
    "\n",
    "    # evaluation\n",
    "    print('the records failed to predict...')\n",
    "    display(ds[results.predicted==-1].head())\n",
    "    \n",
    "    results = results[results.predicted>-1]\n",
    "    print(f'prediction percentage: {results.shape[0]/ds.shape[0]}')\n",
    "    \n",
    "    y_actual = results.actual.values\n",
    "    y_predicted = results.predicted.values\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    cm = confusion_matrix(y_actual, y_predicted, labels=clf.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    print(pd.Series(le.inverse_transform(clf.classes_)))\n",
    "\n",
    "    acc = accuracy_score(y_actual, y_predicted)\n",
    "    p = precision_score(y_actual, y_predicted, average='macro')\n",
    "    r = recall_score(y_actual, y_predicted, average='macro')\n",
    "    f1 = f1_score(y_actual, y_predicted, average='macro')\n",
    "\n",
    "    print(f'prediction accuracy is {acc}; precision:{p}; recall: {r}; f1 score： {f1}')\n",
    "    \n",
    "    return acc, p, r, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89c6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(train_set, t, min_df, max_df, alpha, s_count):\n",
    "    \"\"\"\n",
    "    Fit the estimator on train_set with the tuned hyperparameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_set : DataFrame\n",
    "    t : float\n",
    "    min_df : int\n",
    "    max_df : int\n",
    "    alpha : float\n",
    "    s_count : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model : dict\n",
    "        Items are lable encoder, tfidf vectorizer, and classifier.\n",
    "    \"\"\"          \n",
    "    print('generate features...')\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
    "    \n",
    "    # balance training set\n",
    "    balanced_train_set = get_balanced_training_set(train_set, s_count)\n",
    "    \n",
    "    # features\n",
    "    tfidf = tfidf_vectorizer.fit(balanced_train_set['content'])\n",
    "\n",
    "    X_train = pd.DataFrame(tfidf.transform(balanced_train_set['content']).toarray(), columns=tfidf.get_feature_names_out())\n",
    "    print(f'features: {X_train.shape}')\n",
    "    \n",
    "    print('encode target...')\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    target = le.fit_transform(balanced_train_set['theme'])\n",
    "\n",
    "    # estimator\n",
    "    print('fit estimator...')\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    \n",
    "    clf.fit(X_train, target)\n",
    "    \n",
    "    # save model\n",
    "    model = {\n",
    "        'le': le,\n",
    "        'clf': clf,\n",
    "        'vectorizer': tfidf_vectorizer,\n",
    "        'tfidf': tfidf\n",
    "    }\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48207290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(train_set, save_name, t, min_df, max_df, alpha, s_count=200):\n",
    "    \"\"\"\n",
    "    Save the estimator with the best hyperparameter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_set : DataFrame\n",
    "    save_name : str\n",
    "    t : float\n",
    "    min_df : int\n",
    "    max_df : int\n",
    "    alpha : float\n",
    "    s_count : int, default 200\n",
    "    \"\"\"\n",
    "       \n",
    "    # directory\n",
    "    dir_path = os.path.join(data_path, 'models')\n",
    "    save_path = os.path.join(dir_path, save_name)\n",
    "    \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        \n",
    "    model = create_model(train_set, t, min_df, max_df, alpha, s_count)\n",
    "    \n",
    "    pickle.dump(model, open(save_path, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41023dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_unseen, model, t=0):\n",
    "    \"\"\"\n",
    "    Predict the themes of df_unseen.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_unseen : DataFrame\n",
    "    model : str or dict\n",
    "        If it is str, it is model path, need to load the model from the path.\n",
    "    t : float\n",
    "        The threshold parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_unseen : DataFrame\n",
    "        Update theme column of df_unseen.\n",
    "    \"\"\"    \n",
    "    df_unseen = df_unseen.copy() \n",
    "    \n",
    "    # get model\n",
    "    if type(model) == str:\n",
    "        model = pickle.load(open(os.path.join(data_path, 'models', model), 'rb'))\n",
    "    \n",
    "    tfidf = model['tfidf']\n",
    "    le = model['le']\n",
    "    clf = model['clf']\n",
    "    tfidf_vectorizer = model['vectorizer']\n",
    "\n",
    "    # predict\n",
    "    print('predict...') # transfer to unicode cuz there is nan\n",
    "    X_unseen = pd.DataFrame(tfidf_vectorizer.transform(df_unseen['content'].values.astype('U')).toarray(), columns=tfidf.get_feature_names_out())\n",
    "    \n",
    "    \n",
    "    # deal with '<Unknown>'    \n",
    "    if t == 0:\n",
    "        y_predicted = clf.predict(X_unseen)\n",
    "        \n",
    "        df_unseen['theme'] = le.inverse_transform(y_predicted)\n",
    "        \n",
    "    else:\n",
    "        print('deal with unknown target...')\n",
    "        y_prob = clf.predict_proba(X_unseen)\n",
    "\n",
    "        # handle threshold\n",
    "        max_prob = y_prob.max(axis=1)\n",
    "        y_predicted = y_prob.argmax(axis=1)\n",
    "\n",
    "        y_predicted[max_prob < t] = -1\n",
    "        \n",
    "        le_dict = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "        le_dict[-1] = '<Unknown>'\n",
    "        \n",
    "        df_unseen['theme'] = y_predicted\n",
    "        \n",
    "        df_unseen['theme'] = df_unseen.theme.map(le_dict)\n",
    "    \n",
    "    return df_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f78ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalization_performance(train_set, test_set, t, min_df, max_df, alpha, s_count):\n",
    "    \"\"\"\n",
    "    Show generalization performance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_set : DataFrame\n",
    "    df_unseen : DataFrame\n",
    "    t : float\n",
    "    min_df : int\n",
    "    max_df : int\n",
    "    alpha : float\n",
    "    s_count : int\n",
    "    \"\"\"\n",
    "    # get predicted test\n",
    "    model = create_model(train_set, t, min_df, max_df, alpha, s_count)\n",
    "    predicted_test_set = predict(test_set, model, t)\n",
    "    \n",
    "    y_actual = test_set['theme']\n",
    "    y_predicted = predicted_test_set['theme']\n",
    "    \n",
    "    # evaluation\n",
    "    count_unpredicted = (y_predicted=='<Unknown>').sum()\n",
    "    \n",
    "    print(f'{count_unpredicted} records failed to predict...')\n",
    "    \n",
    "    print(f'prediction coverage: {1 - count_unpredicted / y_predicted.shape[0]}')\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_actual.append(y_predicted))\n",
    "    \n",
    "    y_actual = le.transform(y_actual)\n",
    "    y_predicted = le.transform(y_predicted)\n",
    "\n",
    "    acc = accuracy_score(y_actual, y_predicted)\n",
    "    p = precision_score(y_actual, y_predicted, average='macro')\n",
    "    r = recall_score(y_actual, y_predicted, average='macro')\n",
    "    f1 = f1_score(y_actual, y_predicted, average='macro')\n",
    "    \n",
    "    print(acc, p, r, f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409dce9",
   "metadata": {},
   "source": [
    "# Classification: Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b41a98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(results, para_options):\n",
    "    \"\"\"\n",
    "    Get accuracy Series from results list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results : list of tuples\n",
    "        The item is the return value of function evaluate_classification()\n",
    "    para_options : list of int\n",
    "        The item is candidates of the hyperparameters to be tuned.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        Columns are metrics, rows are parameter available.\n",
    "    best : int or float\n",
    "        The best value in the candidates.\n",
    "    \"\"\"\n",
    "    if len(para_options) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    df = pd.DataFrame(results, index=para_options, columns=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "    \n",
    "    best = para_options[df.accuracy.argmax()]\n",
    "\n",
    "    print(f'The best parameter is {best}.')\n",
    "    \n",
    "    return df, best\n",
    "\n",
    "\n",
    "def tune_hyperparameters(df_train, t_l, min_df_l, max_df_l, alpha_l, s_count_l):\n",
    "    \"\"\"\n",
    "    Get the best min_df and max_df for Vectorizer and parameters for estimator.\n",
    "    The parameter will be tuned separately, will not be tuned in a parameter combination way.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train : DataFrame\n",
    "    t_l : list of float\n",
    "    min_df_l : list of int\n",
    "    max_df_l : list of int\n",
    "    alpha_l : list of float\n",
    "    s_count_l : list of int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of Series\n",
    "        The item is accuracy Series for each parameter.\n",
    "    tuple of Series\n",
    "        The item is precision Series for each parameter.\n",
    "    tuple of DataFrame\n",
    "        Each item is the performance result.\n",
    "    tuple of float\n",
    "        Each item is the best value of the parameter.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # tune min_df\n",
    "    print('tune min_df...')\n",
    "    for min_df in min_df_l:\n",
    "        print(f'min_df={min_df}')\n",
    "        \n",
    "        results.append(evaluate_classification(df_train, 0, min_df, 50)) # in case memory issue for permit\n",
    "        \n",
    "    min_df_metrics, best_min_df = get_accuracy(results, min_df_l)\n",
    "    \n",
    "    # tune max_df\n",
    "    results = []\n",
    "    \n",
    "    print('tune max_df...')\n",
    "    \n",
    "    for max_df in max_df_l:\n",
    "        print(f'max_df={max_df}')\n",
    "        results.append(evaluate_classification(df_train, 0, 10, max_df))\n",
    "        \n",
    "    max_df_metrics, best_max_df = get_accuracy(results, max_df_l)\n",
    "    \n",
    "    # tune alpha\n",
    "    results = []\n",
    "    \n",
    "    print('tune alpha...')\n",
    "    \n",
    "    for alpha in alpha_l:\n",
    "        print(f'alpha={alpha}')\n",
    "        results.append(evaluate_classification(df_train, 0, 5, 50, alpha))\n",
    "        \n",
    "    alpha_metrics, best_alpha = get_accuracy(results, alpha_l)\n",
    "    \n",
    "    # tune thereshold for 'unknown'\n",
    "    results = []\n",
    "    \n",
    "    print('tune threshold...')\n",
    "    \n",
    "    for t in t_l:\n",
    "        print(f't={t}')\n",
    "        results.append(evaluate_classification(df_train, t))\n",
    "        \n",
    "    t_metrics, best_t = get_accuracy(results, t_l)\n",
    "    \n",
    "    # tune sample count\n",
    "    results = []\n",
    "    \n",
    "    print('tune sample count...')\n",
    "    \n",
    "    for s_count in s_count_l:\n",
    "        print(f's_count={s_count}')\n",
    "        results.append(evaluate_classification(df_train, 0, 5, 50, 1, s_count))\n",
    "        \n",
    "    s_metrics, best_s = get_accuracy(results, s_count_l)\n",
    "    \n",
    "    return (min_df_metrics, max_df_metrics, alpha_metrics, t_metrics, s_metrics),\\\n",
    "           (best_min_df, best_max_df, best_alpha, best_t, best_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d288ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_event_with_theme(df_event_original, train, unseen, filepath):\n",
    "    \"\"\"\n",
    "    Add the predicted theme column to the original event table and save to local.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event_original : DataFrame\n",
    "    train : DataFrame\n",
    "    unseen : DataFrame\n",
    "        The column theme has beed predicted.\n",
    "    filepath : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    # combine theme\n",
    "    df_theme = pd.concat([train[['index', 'theme']], unseen[['index', 'theme']]]).set_index('index')\n",
    "\n",
    "    # merge into original event\n",
    "    if 'theme' in df_event_original.columns:\n",
    "        df_event_original = df_event_original.drop('theme', axis=1)\n",
    "        \n",
    "    df_event_original = df_event_original.join(df_theme)\n",
    "\n",
    "    # save to local\n",
    "    df_event_original.to_excel(os.path.join(sub_event_path, filepath), index=False, freeze_panes=(1, 2))\n",
    "    \n",
    "    return df_event_original\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae704011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud_for_event(df, prefix=''):\n",
    "    \"\"\"\n",
    "    Generate and show wordcloud for each theme of the given event.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame contains at least columns: theme and content.\n",
    "    prefix : str, default ''\n",
    "        The prefix for wordcloud pictures.\n",
    "    \"\"\"\n",
    "    print('Prevalent words in each Theme')\n",
    "\n",
    "    # all data\n",
    "    df_freq, freq_dict = get_frequency_table(df['content'])\n",
    "    show_wordcloud(freq_dict, title = prefix + 'All data')\n",
    "\n",
    "    # by theme\n",
    "    for t in df.theme.unique():\n",
    "        df_freq, freq_dict = get_frequency_table(df.loc[df.theme == t, 'content'])\n",
    "\n",
    "        show_wordcloud(freq_dict, title = prefix + t)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c25d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0422b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
