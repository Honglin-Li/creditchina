{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301e3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "event5_processing\n",
    "\n",
    "Processing event5 commitment.\n",
    "\"\"\"\n",
    "\n",
    "# for jupyter notebook\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parents[0].parents[0]))\n",
    "\n",
    "from src.data_transformation.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d096cb",
   "metadata": {},
   "source": [
    "df_event = pd.read_excel(os.path.join(sub_event_path, '51_event_commitment_implementation.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62345dfa",
   "metadata": {},
   "source": [
    "# manual check those rows without region info\n",
    "auth_col = '承诺受理单位 Commitment processing unit'\n",
    "\n",
    "t = extract_authorites(df_event[auth_col]).join(df_event[auth_col])\n",
    "\n",
    "# show the rows without region, to identify posibble region dict\n",
    "s_auth = t.loc[t.level=='uncertain', auth_col].value_counts()\n",
    "\n",
    "print(f'unknown records: {s_auth.sum()}')\n",
    "print(f'unique unknown records: {s_auth.shape}')\n",
    "\n",
    "# check 50 one time\n",
    "s_auth[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22fbcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_regions(df_event):\n",
    "    \"\"\"\n",
    "    Add region related columns to df_event.\n",
    "    \n",
    "    This function is implemented by calling :func:`utils.extract_authorites`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        df_event with region columns.\n",
    "    \"\"\"\n",
    "    # some authorities have no 省 市 区ending, finding the dict by manual checking the rows where level='uncertain'\n",
    "    replace_dict = {\n",
    "        '榆阳': '陕西省榆林市榆阳区',\n",
    "        '许继': '河南省许昌市许继',\n",
    "        '仙人岛': '辽宁省营口市盖州市仙人岛',\n",
    "        '平煤隆基新能源科技有限公司': '河南省许昌市襄城县平煤隆基新能源科技有限公司',\n",
    "        '水源镇': '甘肃省金昌市永昌县水源镇',\n",
    "        '上清寺': '重庆市渝中区上清寺',\n",
    "        '甘孜州': '四川省甘孜藏族自治州',\n",
    "        '中纺院绿色纤维股份公司': '河南省新乡市中纺院绿色纤维股份公司',\n",
    "        '柿铺街道': '湖北省襄阳市樊城区柿铺街道',\n",
    "        '王寨街道': '湖北省襄阳市樊城区王寨街道',\n",
    "        '七星岗街道': '重庆市渝中区七星岗街道',\n",
    "        '鼓浪屿': '福建省厦门市思明区鼓浪屿',\n",
    "        '清河口街道': '湖北省襄阳市樊城区清河口街道',\n",
    "        '化龙桥街道': '重庆市渝中区化龙桥街道',\n",
    "        '上清寺街道': '重庆市渝中区上清寺街道',\n",
    "        '中国有色金属工业第六冶金建设有限公司': '河南省郑州市中原区中国有色金属工业第六冶金建设有限公司',\n",
    "        '淄川': '山东省淄博市淄川区',\n",
    "        '菜园坝街道': '重庆市渝中区菜园坝街道',\n",
    "        '解放碑街道': '重庆市渝中区解放碑街道',\n",
    "        '汉江街道': '湖北省襄阳市樊城区汉江街道',\n",
    "        '上蔡牧原农牧有限公司': '河南省南阳市上蔡牧原农牧有限公司',\n",
    "        '太平店镇': '湖北省襄阳市樊城区太平店镇',\n",
    "        '襄城': '河南省许昌市襄城县',\n",
    "        '古港镇': '湖南省浏阳市古港镇',\n",
    "        '延津': '河南省新乡市延津县',\n",
    "        '汝南': '河南省驻马店市汝南县',\n",
    "        '长垣': '河南省长垣市',\n",
    "        '辛店': '山东省淄博市临淄区辛店',\n",
    "        '大溪沟街道': '重庆市渝中区大溪沟街道'\n",
    "    }\n",
    "    \n",
    "    s_auth = \\\n",
    "    df_event['承诺受理单位 Commitment processing unit'].replace(r'[a-zA-Z\\d]+', '', regex=True).replace(replace_dict, regex=True)\n",
    "    \n",
    "    # get region info\n",
    "    df_region = extract_authorites(s_auth)\n",
    "\n",
    "    # append to original df: province, city, area, level\n",
    "    return df_event.join(df_region) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88c33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event():\n",
    "    \"\"\"\n",
    "    Add region columns to df_event, then get cross tables.\n",
    "    \n",
    "    This func add category columns to df_event, then save processed df_event to local. \n",
    "    Then generate, save, and return cross tables of company and categories and cross tables of [company, year] and categoreis.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_crosstab_event : DataFrame\n",
    "        Cross tables of company and categories.\n",
    "    df_crosstab_event_year : DataFrame\n",
    "        Cross tables of [company, year] and categoreis.\n",
    "    df_period : DataFrame\n",
    "        Data from each time point.\n",
    "    \"\"\"\n",
    "    # load event\n",
    "    print('load data...')\n",
    "    df_event = pd.read_excel(os.path.join(sub_event_path, '51_event_commitment_implementation.xlsx'))\n",
    "    \n",
    "    # rename\n",
    "    df_event.rename(columns={\n",
    "        '承诺类型 Commitment type': 'commit_type',\n",
    "        '承诺事由 Commitment reason': 'commit_reason'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # translate commit type\n",
    "    commit_type_map = {\n",
    "            '主动型': 'Proactive',\n",
    "            '审批替代型': 'Approval substitution',\n",
    "            '证明事项型': 'Certification matters',\n",
    "            '行业自律型': 'Industry self-regulation',\n",
    "            '信用修复型': 'Credit repair'\n",
    "        }\n",
    "\n",
    "    df_event.commit_type = df_event.commit_type.replace(commit_type_map)\n",
    "    \n",
    "    print('add columns: region, law, fine amount, type...')\n",
    "    \n",
    "    df_event = df_event.pipe(add_regions)\n",
    "    \n",
    "    # handle unknown provinces\n",
    "    df_event = standard_province_names(df_event)\n",
    "    \n",
    "    draw_distribution(\n",
    "        [df_event.start_year, df_event.province, df_event.level, df_event.commit_type],\n",
    "        ['bar', 'pie', 'pie', 'pie']\n",
    "    )\n",
    "\n",
    "    print('save processed df_event...')\n",
    "    \n",
    "    df_event[['company_name', \n",
    "               'theme',\n",
    "               'province',\n",
    "               'level',\n",
    "               'authority',\n",
    "               'commit_type',\n",
    "               'commit_reason',\n",
    "               'start_year',\n",
    "               'start_date'\n",
    "              ]].to_excel(os.path.join(processed_event_path, 'event5.xlsx'), \n",
    "                          index=False, \n",
    "                          freeze_panes=(1, 1))\n",
    "\n",
    "    print('generate cross tables...')\n",
    "    \n",
    "    # set parameters\n",
    "    cat_column_names = ['level', 'theme', 'commit_type']\n",
    "    cat_prefix = ['E5_Auth_level:', 'E5_Theme:', 'E5_Commit_Type:']\n",
    "    number_column_name = 'commit'\n",
    "    multi_flags = [False, False, False]\n",
    "    save_prefix = 'event5'\n",
    "    start_year_col = 'start_year'\n",
    "    start_date_col = 'start_date'\n",
    "    \n",
    "    return create_all_crosstabs(df_event,\n",
    "                                cat_prefix, \n",
    "                                cat_column_names, \n",
    "                                number_column_name, \n",
    "                                multi_flags,\n",
    "                                save_prefix,\n",
    "                                start_year_col,\n",
    "                                start_date_col\n",
    "                                )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216ac35",
   "metadata": {},
   "source": [
    "process_event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61baec04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
