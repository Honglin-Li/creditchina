{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dcf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "utils\n",
    "\n",
    "A Module to provide utility functions for the package.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2712f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import date\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import cpca\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# multiprocessing\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "#from pandarallel import pandarallel\n",
    "\n",
    "tqdm.pandas()\n",
    "#pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189ead46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for jupyter notebook\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parents[0].parents[0]))\n",
    "\n",
    "from src.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c70bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# for notebook\n",
    "#%matplotlib inline\n",
    "\n",
    "font_path = os.path.join(data_path, 'simsun.ttc')\n",
    "prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"]=[\"simsun\"] \n",
    "plt.rcParams[\"axes.unicode_minus\"]=False\n",
    "\n",
    "# for multiprocessing\n",
    "cpu_count = os.cpu_count()\n",
    "\n",
    "# load when need\n",
    "df_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f08c7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install chinese province city area package\n",
    "#!pip install cpca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd8b2d",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ymd(s):\n",
    "    \"\"\"\n",
    "    Parse string of year-month-day to date type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str\n",
    "        The format is yyyy-mm-dd.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Date\n",
    "    \"\"\"\n",
    "    year, month, day = s.split('-')\n",
    "    return date(int(year), int(month), int(day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "975ff3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta():\n",
    "    \"\"\"\n",
    "    Load metadata and metadata_year tables.\n",
    "    \"\"\"\n",
    "    df_meta = pd.read_excel(os.path.join(processed_data_path, 'metadata.xlsx'))\n",
    "    df_meta_year = pd.read_excel(os.path.join(processed_data_path, 'metadata_year.xlsx'), index_col=[0, 1, 2])\n",
    "    \n",
    "    return df_meta, df_meta_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa860551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_event_paths(name):\n",
    "    \"\"\"\n",
    "    Get paths of meta tables of a given event(identified by name).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Part file name of 3 table, e.g. event4.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    crosstab_path : str\n",
    "    crosstab_year_path : str\n",
    "    crosstab_day_path : str\n",
    "    \"\"\"\n",
    "    # file name\n",
    "    crosstab_name = 'crosstab_' + name + '.xlsx'\n",
    "    crosstab_year_name = 'crosstab_year_' + name + '.xlsx'\n",
    "    crosstab_day_name = 'crosstab_day_' + name + '.xlsx'\n",
    "    \n",
    "    # file path\n",
    "    crosstab_path = os.path.join(processed_meta_event_path, crosstab_name)\n",
    "    crosstab_year_path = os.path.join(processed_meta_event_path, crosstab_year_name)\n",
    "    crosstab_day_path = os.path.join(processed_meta_event_path, crosstab_day_name)\n",
    "    \n",
    "    return crosstab_path, crosstab_year_path, crosstab_day_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee27843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meta_events(crosstab, crosstab_year, crosstab_day, name):\n",
    "    \"\"\"\n",
    "    Save two types of cross tables to local.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    crosstab : DataFrame\n",
    "        Cross table of company and categories.\n",
    "    crosstab_year : DataFrame\n",
    "        Cross table of [company, year] and categories which has MultiIndex.\n",
    "    crosstab_day : DataFrame\n",
    "        The DataFrame contains columns: ID, company_name, date, number.\n",
    "    name : str\n",
    "        Part file name of crosstabs.\n",
    "    \"\"\"\n",
    "    crosstab_path, crosstab_year_path, crosstab_day_path = get_meta_event_paths(name)\n",
    "    \n",
    "    crosstab.to_excel(\n",
    "        crosstab_path,\n",
    "        freeze_panes=(1, 2))\n",
    "    \n",
    "    crosstab_year.to_excel(\n",
    "        crosstab_year_path, \n",
    "        freeze_panes=(1, 3))\n",
    "    \n",
    "    crosstab_day.to_excel(\n",
    "        crosstab_day_path, \n",
    "        freeze_panes=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e78ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie\n",
    "def draw_distribution_pie(s):\n",
    "    \"\"\"\n",
    "    Show value_counts DataFrame and draw a pie chart.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s : Series\n",
    "        The data source.\n",
    "    \"\"\"\n",
    "    # consider list series\n",
    "    if isinstance(s[0], list):\n",
    "        s = s.explode()\n",
    "    \n",
    "    dist = s.value_counts()\n",
    "    display(dist.to_frame())\n",
    "    pie = plt.pie(dist, labels = dist.index, autopct='%.1f%%')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce8978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar\n",
    "def draw_bar(s):\n",
    "    \"\"\"\n",
    "    Show value_counts DataFrame and draw a bar chart.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s : Series\n",
    "        The data source.\n",
    "    \"\"\"\n",
    "    dist = s.value_counts().sort_index()\n",
    "    display(dist.to_frame())\n",
    "    b = plt.bar(dist.index, dist)\n",
    "    plt.bar_label(b)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e73405",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_type_dict = {\n",
    "    'pie': draw_distribution_pie,\n",
    "    'bar': draw_bar\n",
    "}\n",
    "\n",
    "def draw_distribution(data_list, type_list):\n",
    "    \"\"\"\n",
    "    Show value_counts DataFrame and draw a bar chart for each given data and type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_list : list of Series\n",
    "    type_list : list of str\n",
    "        The item value can be one of the keys of pic_type_dict\n",
    "    \"\"\"   \n",
    "    print('check distributions...')\n",
    "    \n",
    "    for data, pic_type in zip(data_list, type_list):\n",
    "        pic_type_dict[pic_type](data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62cd023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_law(x):\n",
    "    \"\"\"\n",
    "    Extract law name from text(in penalty context, the text is penalty basis & type of illegal behavior).\n",
    "    \n",
    "    The extracting rules: \n",
    "    1. basis with《》, extract the law inside the marks;\n",
    "    2. else if basis contains 第XX条, extract from start to the position;\n",
    "    3. else keep the basis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : str\n",
    "        The text contains the name of law.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Law name.\n",
    "    \"\"\"\n",
    "    x = str(x)\n",
    "    if ('《' in x ) and ('》' in x):\n",
    "        return x[x.find('《') : x.find('》') + 1]\n",
    "    \n",
    "    match = re.search(r'第\\w*条', x)\n",
    "    if match:\n",
    "        return x[:match.start()]\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b365e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_province_names(df_event, province_col_name='province'):\n",
    "    \"\"\"\n",
    "    Mainly change the provinces which are not in province list to NA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "    province_col_name : str, default 'province'\n",
    "        The column name of province column.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    eligible_provinces = pd.read_excel(os.path.join(attri_path, 'regions.xlsx'), sheet_name='province_short').province.tolist()\n",
    "    \n",
    "    unknown_provinces = list(set(df_event['province'])-set(eligible_provinces))\n",
    "    unknow_index = df_event.loc[df_event[province_col_name].isin(unknown_provinces)].index\n",
    "    \n",
    "    if len(unknown_provinces) > 0:\n",
    "        print('Unknown provinces, please check...')\n",
    "        print(unknown_provinces)\n",
    "        \n",
    "        # !!!check if some provinces have no records\n",
    "        check = set(eligible_provinces) - set(df_event[province_col_name])\n",
    "        \n",
    "        if len(check) > 0:\n",
    "            print('those provinces have no records in the event')\n",
    "            print(check)\n",
    "            \n",
    "        # change unknown province name to NA\n",
    "        df_event.loc[unknow_index, province_col_name] = np.nan\n",
    "    \n",
    "    return df_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a3224",
   "metadata": {},
   "source": [
    "# authority related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "709441ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authorites(auth_s):\n",
    "    \"\"\"\n",
    "    Extract pure authorites without region.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    auth_s : array-like\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Contains columns: p, c, a, level, authority\n",
    "    \"\"\"\n",
    "    df_region = extract_regions(auth_s).rename(\n",
    "        columns = {'address': 'authority'}\n",
    "        )\n",
    "    \n",
    "    return df_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb11f78",
   "metadata": {},
   "source": [
    "# category related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_single_choice_category_from_keywords(df_event, cat_column_name, cat_source_column_name, category_dict):\n",
    "    \"\"\"\n",
    "    Add single choice category column to a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "    cat_column_name : str\n",
    "        Name of the new category column.\n",
    "    cat_source_column_name : str\n",
    "        The column which contains the category info.\n",
    "    category_dict : dict of {'search keywords': 'corresponding category'}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        df_event with category column.\n",
    "    \"\"\"  \n",
    "    # extract keywords from reason type\n",
    "    reason_pattern = '|'.join(category_dict.keys())\n",
    "    \n",
    "    df_event[cat_column_name] = df_event[cat_source_column_name].str.extract(f'({reason_pattern})')\n",
    "\n",
    "    # check whether the dict cover all the rows\n",
    "    print('rows that are not covered by mapping dict')\n",
    "    display(df_event[df_event[cat_column_name].isna()])\n",
    "\n",
    "    # fill the new category column\n",
    "    df_event[cat_column_name] = df_event[cat_column_name].map(category_dict)\n",
    "    \n",
    "    return df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_multi_choice_category_from_keywords(df_event, cat_column_name, cat_source_column_name, category_dict):\n",
    "    \"\"\"\n",
    "    Add multi-choice category column to a DataFrame.\n",
    "    \n",
    "    Note: if wanna check whether the dict cover all the rows, run single-choice version.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "    cat_column_name : str\n",
    "        Name of the new category column.\n",
    "    cat_source_column_name : str\n",
    "        The column which contains the category info.\n",
    "    category_dict : dict of {'search keywords': 'corresponding category'}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The category column contains list of multi-categories\n",
    "    \"\"\"  \n",
    "    # extract keywords from reason type\n",
    "    reason_pattern = '|'.join(category_dict.keys())\n",
    "    \n",
    "    df_event[cat_column_name] = df_event[cat_source_column_name].str.findall(f'({reason_pattern})')\n",
    "    \n",
    "    # de-duplicates, get key values\n",
    "    df_event[cat_column_name] = df_event[cat_column_name].apply(lambda x: [category_dict[cat] for cat in set(x)])\n",
    "    \n",
    "    return df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27acce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_table(df_event, start_year_c, start_date_c, period, list_type, list_name='redlist_type'):\n",
    "    \"\"\"\n",
    "    Ger uniformed table which contains columns: company_name, start_year, end_year, start_date, end_date, type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "    start_year_c : str\n",
    "        The name of start year column.\n",
    "    start_date_c : str\n",
    "        The name of start date column.\n",
    "    period : int\n",
    "        The validation years, like 3.\n",
    "        If it is set to a minus number, that's means no validation period, it is set to current end date(2022).\n",
    "    list_type : str\n",
    "        The value of the column list_name, like \"Tax blacklist\".\n",
    "    list_name : str\n",
    "        The column name of type, like \"redlist_type\" or \"blacklist_type\".\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    if df_event.shape[0] == 0:\n",
    "        return pd.DataFrame(columns=['company_name', 'start_year', 'end_year', 'start_date', 'end_date', list_name])\n",
    "    \n",
    "    df_event = df_event[['company_name', start_year_c, start_date_c]].rename(columns={start_year_c: 'start_year',\n",
    "                                                                        start_date_c: 'start_date'})\n",
    "    \n",
    "    if period > 0:\n",
    "        df_event['end_year'] = df_event.start_year + period\n",
    "        df_event['end_date'] = df_event.start_date.apply(lambda x: str(int(x[:4]) + period) + x[4:])\n",
    "    else:\n",
    "        df_event['end_year'] = e_year\n",
    "        df_event['end_date'] = e_date\n",
    "        \n",
    "    df_event[list_name] = list_type\n",
    "    \n",
    "    return df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a374d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_last_column_to_first(df):\n",
    "    \"\"\"\n",
    "    Move the last column to the first column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    # order\n",
    "    c = df.columns.tolist()\n",
    "    \n",
    "    column_order = c[-1:] + c[:-1]\n",
    "    df = df[column_order]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0c9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_margins(df, margin_column_name):\n",
    "    \"\"\"\n",
    "    Add total number column and move to the first column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "    margin_column_name : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    df[margin_column_name] = df.sum(axis=1)\n",
    "    \n",
    "    df = move_last_column_to_first(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_id_to_company(df):\n",
    "    \"\"\"\n",
    "    Add ID to DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    global df_ids\n",
    "    \n",
    "    if not isinstance(df_ids, pd.DataFrame):\n",
    "        df_ids = pd.read_excel(os.path.join(attri_path, 'company_ids.xlsx'))\n",
    "    \n",
    "    return df.merge(df_ids, how='left', on='company_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f45d40",
   "metadata": {},
   "source": [
    "# day-level event-number-table related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7fd73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_df(df_event, no_col, start_date_col='start_date', end_date_col=None):\n",
    "    \"\"\"\n",
    "    Get a DataFrame of event numbers of all the date change points of companies.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "        The DataFrame to work on.\n",
    "    no_col : str\n",
    "        The name of new column which records the event(record) number of corresponding date change point of a company.\n",
    "    start_date_col : str\n",
    "        The name of start date column in df_event.\n",
    "    end_date_col : str, optional\n",
    "        The name of end date column in df_event.\n",
    "        If null, fill end date from config (now: 2022-12-31)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The DataFrame contains columns: ID, company_name, date, no_col.\n",
    "    \"\"\"\n",
    "    period_l = [] # ds for the final DF\n",
    "    \n",
    "    # end_date column\n",
    "    if end_date_col is None:\n",
    "        end_date_col = 'end_date'\n",
    "        df_event[end_date_col] = e_date\n",
    "        \n",
    "    # end_date may be some nan\n",
    "    df_event[end_date_col] = df_event[end_date_col].fillna(e_date)\n",
    "\n",
    "    # columns needed    \n",
    "    df_period = df_event[[\n",
    "        'company_name', \n",
    "        start_date_col, \n",
    "        end_date_col]]\n",
    "\n",
    "    # out-loop: each company\n",
    "    for firm_name, group in df_period.groupby('company_name'):\n",
    "        # create a dict: key-date, value-delta(add/minus)\n",
    "        date_dict = {}\n",
    "\n",
    "        # inner-loop1: each record -> fill out date_dict\n",
    "        for index, row in group.iterrows():\n",
    "            # for start date, delta+1\n",
    "            key = row[start_date_col]\n",
    "            date_dict[key] = date_dict.get(key, 0) + 1\n",
    "\n",
    "            # for end date, delta-1\n",
    "            key = row[end_date_col]\n",
    "            date_dict[key] = date_dict.get(key, 0) - 1\n",
    "\n",
    "        # inner-loop2: each date point -> append final data row\n",
    "        current_number = 0\n",
    "\n",
    "        for date in sorted(date_dict):\n",
    "            if date != e_date: #TODO: check logic, if real expire date is really equal to e_date\n",
    "                current_number += date_dict[date]\n",
    "\n",
    "            period_l.append({\n",
    "                'company_name': firm_name,\n",
    "                'date': date,\n",
    "                no_col: current_number  \n",
    "            })\n",
    "\n",
    "    # to frame, add ID\n",
    "    if len(period_l) == 0:\n",
    "        return pd.DataFrame(columns=['ID', 'company_name', 'date', no_col])\n",
    "    else:\n",
    "        return pd.DataFrame(period_l).pipe(assign_id_to_company).set_index(['ID', 'company_name', 'date'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d337ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_periods(period_l, margin_col_name=None):\n",
    "    \"\"\"\n",
    "    Get a merged period table with margins and ffill in firm groups.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    period_l : list of DataFrame\n",
    "        Each item come from get_period_df().\n",
    "    margin_col_name : str\n",
    "        The name of new margin column.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    # eliminate empty df\n",
    "    period_l = [p for p in period_l if p.shape[0]>0]\n",
    "    \n",
    "    # concat all the period tables\n",
    "    df_period = pd.concat(period_l, join='outer', axis=1).reset_index().sort_values(by=['ID', 'date'], ignore_index=True)\n",
    "\n",
    "    # ffill by company, then add margin\n",
    "    df_period = df_period.groupby('ID').fillna(method='ffill').\\\n",
    "        pipe(assign_id_to_company).\\\n",
    "        set_index(['ID', 'company_name', 'date'])\n",
    "    \n",
    "    if margin_col_name:\n",
    "        df_period = df_period.pipe(add_margins, margin_col_name)\n",
    "    \n",
    "    return df_period\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ec248",
   "metadata": {},
   "source": [
    "# frequency table related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce76ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_year_column(df_event, cat_col_name, start_year, end_year=None):\n",
    "    \"\"\"\n",
    "    Add and explode column: year between start years and end years.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "        The DataFrame to work on.\n",
    "    cat_col_name : str\n",
    "        The categorical column name in df_event.\n",
    "    start_year : str\n",
    "        The start year column name in df_event.\n",
    "    end_year : str, optional\n",
    "        The end year column name in df_event.\n",
    "        If null, fill end year from config (now: 2022)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The processed df_event with 3 columns: company_name, category, year.\n",
    "    \"\"\"\n",
    "    if end_year is None:\n",
    "        end_year = 'end_year'\n",
    "        df_event[end_year] = e_year\n",
    "    \n",
    "    # df: the columns we need    \n",
    "    df = df_event[['company_name', cat_col_name, start_year, end_year]]\n",
    "    df = df.astype({start_year: 'int',\n",
    "               end_year: 'int'})\n",
    "    \n",
    "    # reset years\n",
    "    df[start_year] = df[start_year].apply(lambda x: max(x, s_year))\n",
    "    df[end_year] = df[end_year].apply(lambda x: min(x, e_year))\n",
    "    \n",
    "    # check end_year>start_year, then delete\n",
    "    tmp = df[end_year] - df[start_year]\n",
    "    del_id = tmp[tmp < 0].index\n",
    "    df.drop(del_id, inplace=True)\n",
    "    \n",
    "    # get year list then explode\n",
    "    df['year'] = df.apply(lambda x: list(range(x[start_year], x[end_year]+1)), axis=1)\n",
    "    df = df.explode('year', ignore_index=True).drop([start_year, end_year], axis=1)\n",
    "    \n",
    "    # may exist duplicate years after explode\n",
    "    #df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53d9383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosstab(df, prefix, cat_col_name, multi_flag=False):\n",
    "    \"\"\"\n",
    "    Get cross table for company and single-choice & multi-choice categories.\n",
    "    \n",
    "    For multi-choice categories, explode the category column first.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame to work on.\n",
    "    prefix : str\n",
    "        Prefix to new category columns.\n",
    "    cat_col_name : str\n",
    "        The categorical column name in df_event.\n",
    "    multi_flag : bool, default False\n",
    "        Flag to show the category is single choice or multi-choice.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The cross table with ID.\n",
    "    \"\"\"        \n",
    "    if multi_flag:\n",
    "        df = df.explode(cat_col_name, ignore_index=True)\n",
    "        \n",
    "    df_freq = pd.crosstab(index=df['company_name'], \n",
    "                          columns=df[cat_col_name]\n",
    "                         ).add_prefix(prefix).reset_index().pipe(assign_id_to_company).set_index(['ID', 'company_name'])\n",
    "    \n",
    "    return df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f0a653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosstab_by_year(df, prefix, cat_col_name, start_year, end_year=None, multi_flag=False):\n",
    "    \"\"\"\n",
    "    Get cross table for [company, year] and categories.\n",
    "    \n",
    "    For multi-choice categories, explode the category column first.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame to work on.\n",
    "    prefix : str\n",
    "        Prefix to new category columns.\n",
    "    cat_col_name : str\n",
    "        The categorical column name in df_event.\n",
    "    start_year : str\n",
    "        The start year column name in df_event.\n",
    "    end_year : str, optional\n",
    "        The end year column name in df_event.\n",
    "    multi_flag : bool, default False\n",
    "        Flag to show the category is single choice or multi-choice.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The cross table with MultiIndex.\n",
    "    \"\"\"    \n",
    "    if multi_flag:\n",
    "        df = df.explode(cat_col_name, ignore_index=True)\n",
    "        \n",
    "    df = prepare_year_column(df, cat_col_name, start_year, end_year)\n",
    "    # now, the df contains 3 columns: company_name, cat_columne, year, run crosstab to get frequency table\n",
    "            \n",
    "    return pd.crosstab(\n",
    "        index=[df['company_name'], df['year']], \n",
    "        columns=df[cat_col_name]\n",
    "    ).add_prefix(prefix).reset_index().pipe(assign_id_to_company).set_index([\n",
    "        'ID',\n",
    "        'company_name',\n",
    "        'year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5543d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosstabs_for_multi_categories(df_event, cat_prefix, cat_column_names, number_column_name, multi_flags):\n",
    "    \"\"\"\n",
    "    Get cross tables for company and multiple categories.\n",
    "    \n",
    "    Better be sure the first category is a single-choice category, so that the total number is corresponding to real record number.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "        The DataFrame to work on.\n",
    "    cat_prefix : list of str\n",
    "        The corresponding prefix to new category columns.\n",
    "    cat_column_names : list of str\n",
    "        The corresponding categorical column name in df_event.\n",
    "    number_column_name : str\n",
    "        The name of total number column.    \n",
    "    multi_flags : list of bool\n",
    "        Indicate the category column is multi-choice or not.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The cross table for multiple categories which contains company_name, ID, #number, category columns.\n",
    "    \"\"\"\n",
    "    dfs_freq = []\n",
    "    \n",
    "    for c, p, f in zip(cat_column_names, cat_prefix, multi_flags):\n",
    "        dfs_freq.append(\n",
    "            get_crosstab(df_event, p, c, f)\n",
    "        )\n",
    "    \n",
    "    # add total numbers to the first df_freq\n",
    "    dfs_freq[0] = add_margins(dfs_freq[0], number_column_name)\n",
    "\n",
    "    \n",
    "    return pd.concat(dfs_freq, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bad70a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosstabs_for_multi_categories_by_year(df_event, cat_prefix, cat_column_names, number_column_name, multi_flags, start_year, end_year=None):\n",
    "    \"\"\"\n",
    "    Get cross tables for [company, year] and multiple categories.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "        The DataFrame to work on.\n",
    "    cat_prefix : list of str\n",
    "        The corresponding prefix to new category columns.\n",
    "    cat_column_names : list of str\n",
    "        The corresponding categorical column name in df_event.\n",
    "    number_column_name : str\n",
    "        The name of total number column.\n",
    "    multi_flags : list of bool\n",
    "        Indicate the category column is multi-choice or not.\n",
    "    start_year : str\n",
    "        The start year column name in df_event.\n",
    "    end_year : str, optional\n",
    "        The end year column name in df_event.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The cross table for multiple categories which contains MultiIndex(company_name, ID, year), #number, category columns.\n",
    "    \"\"\"    \n",
    "    if end_year is None:\n",
    "        end_year = 'end_year'\n",
    "        df_event[end_year] = e_year\n",
    "        \n",
    "    dfs_freq = []\n",
    "\n",
    "    # get freq_df by year for each category\n",
    "    for c, p, f in zip(cat_column_names, cat_prefix, multi_flags):\n",
    "        tmp = get_crosstab_by_year(\n",
    "            df_event, \n",
    "            p, \n",
    "            c, \n",
    "            start_year, \n",
    "            end_year,\n",
    "            f\n",
    "        )\n",
    "\n",
    "        dfs_freq.append(tmp)\n",
    "\n",
    "    # add total numbers    \n",
    "    dfs_freq[0] = add_margins(dfs_freq[0], number_column_name)\n",
    "    \n",
    "    # -------for df_meta_year_eventX: details\n",
    "    df_freq_year = pd.concat(dfs_freq, axis=1)\n",
    "    \n",
    "    return df_freq_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db7f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_crosstabs(\n",
    "    df_event,\n",
    "    cat_prefix, \n",
    "    cat_column_names, \n",
    "    number_column_name, \n",
    "    multi_flags,\n",
    "    save_prefix,\n",
    "    start_year_col,\n",
    "    start_date_col,\n",
    "    end_year_col=None,\n",
    "    end_date_col=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Genarate, Save and Return crosstab, crosstab_year, crosstab_period for one given event.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_event : DataFrame\n",
    "        The DataFrame to work on.\n",
    "    cat_prefix : list of str\n",
    "        The corresponding prefix to new category columns.\n",
    "    cat_column_names : list of str\n",
    "        The corresponding categorical column name in df_event.\n",
    "    number_column_name : str\n",
    "        The name of total number column.\n",
    "    multi_flags : list of bool\n",
    "        Indicate the category column is multi-choice or not.\n",
    "    save_prefix : str\n",
    "        The prefix of file name of 3 crosstabs.\n",
    "    start_year_col : str\n",
    "        The start year column name in df_event.\n",
    "    end_year_col : str, optional\n",
    "        The end year column name in df_event.\n",
    "    start_date_col : str\n",
    "        The start year column name in df_event.\n",
    "    end_date_col : str, optional\n",
    "        The end year column name in df_event.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_crosstab_event : DataFrame\n",
    "    df_crosstab_event_year : DataFrame\n",
    "    df_period : DataFrame\n",
    "    \"\"\"  \n",
    "    print('generate cross tables of campany and categories...')\n",
    "\n",
    "    df_crosstab_event = get_crosstabs_for_multi_categories(\n",
    "        df_event, \n",
    "        cat_prefix, \n",
    "        cat_column_names, \n",
    "        number_column_name, \n",
    "        multi_flags\n",
    "    )\n",
    "    \n",
    "    print('generate cross tables of [campany, year] and categories...')\n",
    "\n",
    "    df_crosstab_event_year = get_crosstabs_for_multi_categories_by_year(\n",
    "        df_event, \n",
    "        cat_prefix, \n",
    "        cat_column_names, \n",
    "        number_column_name,\n",
    "        multi_flags,\n",
    "        start_year_col,\n",
    "        end_year_col\n",
    "    )\n",
    "    \n",
    "    print('generate period table of [ID, company, date] and number...')\n",
    "    \n",
    "    df_period = get_period_df(df_event, number_column_name, start_date_col, end_date_col)\n",
    "    \n",
    "    save_meta_events(df_crosstab_event, df_crosstab_event_year, df_period, save_prefix)\n",
    "    \n",
    "    return df_crosstab_event, df_crosstab_event_year, df_period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b616480",
   "metadata": {},
   "source": [
    "# region related functions\n",
    "\n",
    "extract region, level ,province, city, area from authroties and regions.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9726ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_region_level(row): # from province, county, city columns\n",
    "    \"\"\"\n",
    "    Assign region level(province, city, area) to the row.\n",
    "    \n",
    "    This func is used in :meth:`pandas.DataFrame.apply`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row : array-like\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Return the region level\n",
    "    \"\"\"\n",
    "    if pd.notnull(row['area']):\n",
    "        return 'area'\n",
    "    if pd.notnull(row['city']):\n",
    "        return 'city'\n",
    "    if pd.notnull(row['province']):\n",
    "        return 'province'\n",
    "\n",
    "    return 'uncertain'\n",
    "\n",
    "\n",
    "def fill_pca(row, pca, address_pattern): # for NA\n",
    "    \"\"\"\n",
    "    Fill pca(province, city, area) for rows.\n",
    "    \n",
    "    This func is used in :meth:`pandas.DataFrame.apply`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row : array-like\n",
    "        DataFrame row.\n",
    "    pca : DataFrame\n",
    "        A DataFrame which contains pca to full pca info.\n",
    "    address_pattern : regex pattern\n",
    "        A regex pattern to split a full pca to (p, c, a)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (p, c, a)\n",
    "    \"\"\"\n",
    "    if pd.notnull(row['省']):\n",
    "        # some areas are not accounted into area, but in address\n",
    "        if bool(re.match(r'.+区', row['地址'])) & pd.isnull(row['区']):\n",
    "            row['区'] = row['地址']\n",
    "            \n",
    "        return row['省'], row['市'], row['区']\n",
    "    \n",
    "    # dealing with NA: find area-> find corresponding pca in pca -> extract p, c, a from pca\n",
    "    keyword = row['a']\n",
    "\n",
    "    if pd.isnull(row['a']) & pd.notnull(row['c']):\n",
    "        keyword = row['c']\n",
    "    \n",
    "    full_pca = pca.loc[pca['region'] == keyword, 'pca'].tolist()\n",
    "    if len(full_pca) == 1:\n",
    "        full_pca = full_pca[0]\n",
    "        return address_pattern.match(full_pca).groups() # (p, c, a)\n",
    "    else:\n",
    "        return row['p'], row['c'], row['a']\n",
    "    \n",
    "    \n",
    "def extract_regions(region_s):\n",
    "    \"\"\"\n",
    "    Extract region related columns from an address-like column.\n",
    "    \n",
    "    The function firstly use cpca package to extract region info. Then for those who could not be extracted, extract by regex.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region_s : array-like\n",
    "        A column of DataFrame which contains address-like values, can be authority names in our case.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A DataFrame which contains columns: province, city, area, level.\n",
    "        If a region column is needed, it can be attained by concat p, c, a\n",
    "    \"\"\"\n",
    "    # get pca from package\n",
    "    df_region = cpca.transform(region_s)[['省', '市', '区', '地址']]\n",
    "    \n",
    "    # split region to p, c , a\n",
    "    address_pattern = re.compile(r'(?P<p>[^省]+自治区|.*?省|上海市|北京市|天津市|重庆市)?(?P<c>[^市]+自治州|.*?地区|.+盟|.*?市)?(?P<a>[^县]+县|.+区|.+市|.+旗)?')\n",
    "    df_region = df_region.join(region_s.str.extract(address_pattern, expand=True))\n",
    "    \n",
    "    # deal with those which can not be transformed\n",
    "    pca = pd.read_excel(os.path.join(attri_path, 'regions.xlsx'), sheet_name='pca') # province city area\n",
    "    df_pca = df_region.apply(fill_pca, args=(pca, address_pattern), axis=1, result_type='expand')\n",
    "    df_pca.columns = ['province', 'city', 'area']\n",
    "    \n",
    "    # assign level\n",
    "    df_pca['level'] = df_pca.apply(assign_region_level, axis=1)\n",
    "    df_pca = df_pca.join(df_region['地址']).rename(\n",
    "        columns={'地址': 'address'})\n",
    "    \n",
    "    return df_pca # province| city| area| level | address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d65f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
