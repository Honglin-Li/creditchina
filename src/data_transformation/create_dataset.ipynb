{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea61fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create_dataset\n",
    "\n",
    "The module provides functions to create the final dataset and sample data.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da29b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for jupyter notebook\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parents[0].parents[0]))\n",
    "\n",
    "#from utils import processed_data_path, original_path\n",
    "from src.data_transformation.utils import *\n",
    "import os\n",
    "import src.data_transformation.event1_permit_processing as event1_permit\n",
    "import src.data_transformation.event1_penalty_processing as event1_penalty\n",
    "import src.data_transformation.event2_processing as event2\n",
    "import src.data_transformation.event3_processing as event3\n",
    "import src.data_transformation.event4_processing as event4\n",
    "import src.data_transformation.event5_processing as event5\n",
    "from src.data_transformation.split_events import split_events\n",
    "from src.data_transformation.pipeline import *\n",
    "from src.data_transformation.event_stat import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc3a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_credit_dataset():\n",
    "    \"\"\"\n",
    "    Create the credit dataset from the extracted data.\n",
    "    \n",
    "    This evolvs split, pre-processing, and categorize events. Then create metadata(year- and day-level) based on the cleaned events.\n",
    "    The data set is verified by comparing with original metadata.\n",
    "    \"\"\"\n",
    "    # check if the data is downloaded and extracted:\n",
    "    if not os.path.exists(os.path.join(original_path, 'mothers_original.xlsx')):\n",
    "        print('You should download the credit reports and extract the data first before you create data set!!!')\n",
    "        return\n",
    "        \n",
    "    # set parameters\n",
    "    # event column name\n",
    "    file_name_list = ['event1_permit', 'event1_penalty', 'event2', 'event3', 'event4', 'event5']\n",
    "\n",
    "    # func to generate processed events & crosstabs\n",
    "    func_list = [event1_permit.process_event,\n",
    "                 event1_penalty.process_event,\n",
    "                 event2.process_event, \n",
    "                 event3.process_event, \n",
    "                 event4.process_event,\n",
    "                 event5.process_event]\n",
    "\n",
    "    # 1. split and pre-process events\n",
    "    meta_path = os.path.join(processed_data_path, 'metadata.xlsx')\n",
    "    \n",
    "    if not os.path.exists(meta_path):\n",
    "        split_events()\n",
    "    \n",
    "    # remove the incorrect event records\n",
    "    #remove_incorrect_event_records(pd.read_excel(meta_path))\n",
    "\n",
    "    # 2. get crosstabs\n",
    "    print('generating crosstabs for each events...')\n",
    "    crosstabs, crosstabs_year, crosstabs_day = get_crosstab_dataframes(file_name_list, func_list)\n",
    "\n",
    "    # 3. create final dataset\n",
    "    df_meta = get_meta_table(crosstabs, new=False)\n",
    "    df_meta_year = get_meta_year_table(df_meta, crosstabs_year, new=True)\n",
    "    df_meta_day = get_meta_day_table(df_meta, crosstabs_day, new=True)\n",
    "    \n",
    "    # 4. internal check: START YEAR V.S. FOUNDATION YEAR\n",
    "    print('internal consistency check...')\n",
    "    \n",
    "    df_result = internal_consistency_check_year(df_meta, df_meta_year)\n",
    "    \n",
    "    if df_result.shape[0] > 0:\n",
    "        print('year internal consistency check failed!!!')\n",
    "        #display(df_result.head(50))\n",
    "        return df_result\n",
    "    \n",
    "    # 5. credit rating variations\n",
    "    check_rating_variation_types(df_meta_year)\n",
    "    create_metadata_year_for_variation_firms(df_meta_year)\n",
    "    \n",
    "    print('credit category variation tables over time (all, mother, daughter)')\n",
    "    print(get_rating_variation_table(df_meta_year))\n",
    "    \n",
    "    df_meta_year = add_M_D_column(df_meta_year, df_meta)\n",
    "    print(get_rating_variation_table(df_meta_year[df_meta_year.M_D != 'D']))\n",
    "    print(get_rating_variation_table(df_meta_year[df_meta_year.M_D == 'D']))\n",
    "    \n",
    "    \n",
    "    # 6. internal check: compare actual and predicted CREDIT CATEGORY\n",
    "    internal_consistency_check_credit_category(df_meta, df_meta_year)\n",
    "    internal_consistency_check_credit_category(df_meta, df_meta_day, 'day')\n",
    "    \n",
    "    # 7. performance data\n",
    "    df_performance_panel = get_performance_panel_data(df_meta)\n",
    "    \n",
    "    df_combined_panel = get_performance_credit_panel_data(df_performance_panel, df_meta_year) # for regression\n",
    "    \n",
    "    # 8. mother daughter relation & stat\n",
    "    df_relation_panel = get_mother_daughter_relation_panel_data(df_meta, df_meta_year)\n",
    "    \n",
    "    df_relation_stat_panel = get_mother_daughter_stat_panel_data(df_relation_panel)\n",
    "    \n",
    "    # 9. final credit-performance-relation table, for regression considering daughters\n",
    "    df_final_panel = get_performance_credit_relationship_panel_data(df_combined_panel, df_relation_stat_panel)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ed18f",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da91dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_analysis():\n",
    "    \"\"\"\n",
    "    Generate credit tables and reports for analysis.\n",
    "    \n",
    "    The generated analysis is in the data/stat directory.\n",
    "    \"\"\"    \n",
    "    # load data\n",
    "    # meta\n",
    "    df_meta = get_credit_meta_data().reset_index()\n",
    "\n",
    "    no_company = df_meta.shape[0]\n",
    "\n",
    "    # load event\n",
    "    file_name_list = ['event1_permit', 'event1_penalty', 'event2', 'event3', 'event4', 'event5']\n",
    "\n",
    "    event1_permit, event1_penalty, event2, event3, event4, event5 = add_M_D_column_for_list(\n",
    "        get_event_dataframes(file_name_list),\n",
    "        df_meta\n",
    "    ) # add M_D\n",
    "\n",
    "    crosstabs, crosstabs_year, crosstabs_day = get_crosstab_dataframes(file_name_list, [0,0,0,0,0,0])\n",
    "\n",
    "    # load crosstabs\n",
    "    ct1_permit, ct1_penalty, ct2, ct3, ct4, ct5 = add_M_D_column_for_list(\n",
    "        crosstabs,\n",
    "        df_meta\n",
    "    )\n",
    "\n",
    "    ct1_year_permit, ct1_year_penalty, ct2_year, ct3_year, ct4_year, ct5_year = add_M_D_column_for_list(\n",
    "        crosstabs_year,\n",
    "        df_meta\n",
    "    )\n",
    "\n",
    "    #ct1_day_permit, ct1_day_penalty, ct2_day, ct3_day, ct4_day, ct5_day = crosstabs_day\n",
    "    # generate stat for metadata(all firms/ mothers/ daughters)\n",
    "    df_province, df_province_year, df_relation, df_year_company = generate_meta_stat(df_meta, 'stat_meta.xlsx')\n",
    "\n",
    "    df_province_m, df_province_year_m, df_relation_m, df_year_company_m = generate_meta_stat(\n",
    "        df_meta[df_meta.M_D!='D'], 'stat_meta_mothers.xlsx'\n",
    "    )\n",
    "\n",
    "    df_province_d, df_province_year_d, df_relation_d, df_year_company_d = generate_meta_stat(\n",
    "        df_meta[df_meta.M_D=='D'], 'stat_meta_daughters.xlsx'\n",
    "    )\n",
    "\n",
    "    # generate for each stat\n",
    "    generate_event_stat(df_year_company_m, df_year_company_d, event1_permit, ct1_year_permit, 'permit', ['permit_type', 'theme', 'level'], 'start_year', 'end_year')\n",
    "\n",
    "    generate_event_stat(df_year_company_m, df_year_company_d, event1_penalty, ct1_year_penalty, 'penalty', ['penalty_type', 'theme', 'level'])\n",
    "\n",
    "    generate_event_stat(df_year_company_m, df_year_company_d,  event2, ct2_year, 'redlist', ['redlist_type'])\n",
    "\n",
    "    generate_event_stat(df_year_company_m, df_year_company_d,  event3, ct3_year, 'blacklist', ['inclusion_reason', 'theme', 'level'], 'issue_year')\n",
    "\n",
    "    generate_event_stat(df_year_company_m, df_year_company_d,  event4, ct4_year, 'watchlist', ['inclusion_reason', 'level'])\n",
    "\n",
    "    generate_event_stat(df_year_company_m, df_year_company_d,  event5, ct5_year, 'commit', ['commit_type', 'theme', 'level'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97278e3",
   "metadata": {},
   "source": [
    "# Sampling for thesis data submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampled_daughter_list(m_list, sample_count=10):\n",
    "    \"\"\"\n",
    "    Get sampled daughter name list by mother name list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m_list : list of str\n",
    "        A list of parent companies to sample.\n",
    "    sample_count : int, default 10\n",
    "        The sample count for each mother company\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        The list of sampled subsidiry names.\n",
    "    \"\"\"\n",
    "    df_r = get_mother_daughter_relation_panel_data()\n",
    "    df_r = df_r[df_r.mother_name.isin(m_list)]\n",
    "    df_r = df_r[['mother_name', 'daughter_name']].drop_duplicates()\n",
    "    \n",
    "    def sample(df):\n",
    "        if df.shape[0] > sample_count:\n",
    "            return df.sample(sample_count)\n",
    "        else:\n",
    "            return df\n",
    "\n",
    "    return df_r.groupby('mother_name', as_index=False).apply(sample).daughter_name.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83299a8e",
   "metadata": {},
   "source": [
    "create_credit_dateset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6fef0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_for_original(m_list, d_list):\n",
    "    \"\"\"\n",
    "    Create and save the sample original mothers and corresponding daughters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m_list : list of str\n",
    "        A list of parent companies to sample.\n",
    "    \"\"\"\n",
    "    def get_sample_event(xls, event_name, sample_companies):\n",
    "        df_event = pd.read_excel(xls, event_name)\n",
    "        return df_event[df_event.company_name.isin(sample_companies)]\n",
    "    \n",
    "    def create_sample(ori_path, tar_path, company_list):\n",
    "        # read and sample\n",
    "        with pd.ExcelFile(ori_path) as original:\n",
    "            # sampled mothers\n",
    "            df_meta = pd.read_excel(original, 'metadata')\n",
    "            df_meta = df_meta[df_meta[company_name].isin(company_list)]\n",
    "\n",
    "            df_event1 = get_sample_event(original, 'event1', company_list)\n",
    "            df_event2 = get_sample_event(original, 'event2', company_list)\n",
    "            df_event3 = get_sample_event(original, 'event3', company_list)\n",
    "            df_event4 = get_sample_event(original, 'event4', company_list)\n",
    "            df_event5 = get_sample_event(original, 'event5', company_list)\n",
    "        \n",
    "        # save\n",
    "        with pd.ExcelWriter(tar_path) as writer:\n",
    "            df_meta.to_excel(writer, sheet_name='metadata', index=False, freeze_panes=(1, 2))\n",
    "            df_event1.to_excel(writer, sheet_name='event1', index=False, freeze_panes=(1, 1))\n",
    "            df_event2.to_excel(writer, sheet_name='event2', index=False, freeze_panes=(1, 1))\n",
    "            df_event3.to_excel(writer, sheet_name='event3', index=False, freeze_panes=(1, 1))\n",
    "            df_event4.to_excel(writer, sheet_name='event4', index=False, freeze_panes=(1, 1))\n",
    "            df_event5.to_excel(writer, sheet_name='event5', index=False, freeze_panes=(1, 1))\n",
    "    \n",
    "    # original path\n",
    "    m_ori_path = os.path.join(data_dir_path, 'original', 'mothers_original.xlsx')\n",
    "    d_ori_path = os.path.join(data_dir_path, 'original', 'daughters_original.xlsx')\n",
    "    \n",
    "    # sample mothers\n",
    "    create_sample(m_ori_path, os.path.join(original_path, 'mothers_original_sample.xlsx'), m_list)\n",
    "    \n",
    "    # sample daughters\n",
    "    create_sample(d_ori_path, os.path.join(original_path, 'daughters_original_sample.xlsx'), d_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "895efb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_sample_for_original(m_50, d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca306b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
